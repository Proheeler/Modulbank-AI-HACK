{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1\\Anaconda2\\lib\\site-packages\\IPython\\core\\magics\\pylab.py:161: UserWarning: pylab import has clobbered these variables: ['clf']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "from sklearn import ensemble, cross_validation, learning_curve, metrics \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# data analysis and wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "\n",
    "# visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# machine learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv',sep='\\t')\n",
    "test_df = pd.read_csv('test.csv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>336</th>\n",
       "      <th>337</th>\n",
       "      <th>338</th>\n",
       "      <th>339</th>\n",
       "      <th>340</th>\n",
       "      <th>341</th>\n",
       "      <th>342</th>\n",
       "      <th>343</th>\n",
       "      <th>344</th>\n",
       "      <th>345</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.192984</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.195690</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.192984</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.195690</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.289893</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 347 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   0  1  2  3  4  5  6         7  8 ...        336  337  338  \\\n",
       "0           0 NaN  1  0  0  1  0  0  0.136364  0 ...   0.192984    0    1   \n",
       "1           1 NaN  1  0  0  1  0  0  0.181818  0 ...   0.195690    0    1   \n",
       "2           2 NaN  1  0  0  0  0  0  0.090909  0 ...   0.192984    0    1   \n",
       "3           3 NaN  1  0  0  1  0  0  0.090909  0 ...   0.195690    0    1   \n",
       "4           4 NaN  1  0  0  1  0  0  0.090909  0 ...   0.289893    0    0   \n",
       "\n",
       "   339  340       341  342  343  344  345  \n",
       "0    0    0  0.222222    1    1    1    1  \n",
       "1    0    0  0.000000    1    1    1    0  \n",
       "2    0    0  0.222222    1    1    1    0  \n",
       "3    0    0  0.000000    1    1    1    0  \n",
       "4    1    0  0.000000    1    1    1    1  \n",
       "\n",
       "[5 rows x 347 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>336</th>\n",
       "      <th>337</th>\n",
       "      <th>338</th>\n",
       "      <th>339</th>\n",
       "      <th>340</th>\n",
       "      <th>341</th>\n",
       "      <th>342</th>\n",
       "      <th>343</th>\n",
       "      <th>344</th>\n",
       "      <th>345</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.221395</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.241508</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.123067</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.296065</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.178956</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 347 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  0  1  2  3  4  5  6         7  8 ...        336  337  338  339  \\\n",
       "0           0  1  1  0  0  0  0  0  0.090909  0 ...   0.221395    0    1    0   \n",
       "1           1  1  1  0  0  1  0  0  0.090909  0 ...   0.241508    0    1    0   \n",
       "2           2  0  1  0  0  1  0  0  0.090909  0 ...   0.123067    0    1    0   \n",
       "3           3  0  1  0  0  1  0  0  0.136364  0 ...   0.296065    0    0    1   \n",
       "4           4  0  1  0  0  1  0  0  0.136364  0 ...   0.178956    0    0    1   \n",
       "\n",
       "   340       341  342  343  344  345  \n",
       "0    0  0.222222    1    1    1    1  \n",
       "1    0  0.111111    1    1    1    0  \n",
       "2    0  0.444444    1    1    1    1  \n",
       "3    0  0.222222    1    1    1    0  \n",
       "4    0  0.111111    1    1    1    1  \n",
       "\n",
       "[5 rows x 347 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=train_df.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "test_df=test_df.replace([np.inf, -np.inf], np.nan).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>336</th>\n",
       "      <th>337</th>\n",
       "      <th>338</th>\n",
       "      <th>339</th>\n",
       "      <th>340</th>\n",
       "      <th>341</th>\n",
       "      <th>342</th>\n",
       "      <th>343</th>\n",
       "      <th>344</th>\n",
       "      <th>345</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>30500.000000</td>\n",
       "      <td>30500.000000</td>\n",
       "      <td>30500.000000</td>\n",
       "      <td>30500.000000</td>\n",
       "      <td>30500.000000</td>\n",
       "      <td>30500.000000</td>\n",
       "      <td>30500.000000</td>\n",
       "      <td>30500.000000</td>\n",
       "      <td>30500.000000</td>\n",
       "      <td>30500.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>30500.000000</td>\n",
       "      <td>30500.000000</td>\n",
       "      <td>30500.000000</td>\n",
       "      <td>30500.000000</td>\n",
       "      <td>30500.000000</td>\n",
       "      <td>30500.000000</td>\n",
       "      <td>30500.000000</td>\n",
       "      <td>30500.000000</td>\n",
       "      <td>30500.000000</td>\n",
       "      <td>30500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>15249.500000</td>\n",
       "      <td>0.177803</td>\n",
       "      <td>0.977902</td>\n",
       "      <td>0.021934</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.437672</td>\n",
       "      <td>0.000623</td>\n",
       "      <td>0.000721</td>\n",
       "      <td>0.096431</td>\n",
       "      <td>0.003344</td>\n",
       "      <td>...</td>\n",
       "      <td>0.306157</td>\n",
       "      <td>0.489672</td>\n",
       "      <td>0.401607</td>\n",
       "      <td>0.050426</td>\n",
       "      <td>0.001246</td>\n",
       "      <td>0.085858</td>\n",
       "      <td>0.965934</td>\n",
       "      <td>0.985541</td>\n",
       "      <td>0.953803</td>\n",
       "      <td>0.626230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8804.735942</td>\n",
       "      <td>0.382353</td>\n",
       "      <td>0.147006</td>\n",
       "      <td>0.146472</td>\n",
       "      <td>0.012803</td>\n",
       "      <td>0.496108</td>\n",
       "      <td>0.024952</td>\n",
       "      <td>0.026848</td>\n",
       "      <td>0.023719</td>\n",
       "      <td>0.057734</td>\n",
       "      <td>...</td>\n",
       "      <td>0.128760</td>\n",
       "      <td>0.499902</td>\n",
       "      <td>0.490231</td>\n",
       "      <td>0.218826</td>\n",
       "      <td>0.035276</td>\n",
       "      <td>0.165875</td>\n",
       "      <td>0.181401</td>\n",
       "      <td>0.119375</td>\n",
       "      <td>0.209914</td>\n",
       "      <td>0.483812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7624.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.192617</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>15249.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.281274</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>22874.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.450414</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>30499.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 347 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0             0             1             2             3  \\\n",
       "count  30500.000000  30500.000000  30500.000000  30500.000000  30500.000000   \n",
       "mean   15249.500000      0.177803      0.977902      0.021934      0.000164   \n",
       "std     8804.735942      0.382353      0.147006      0.146472      0.012803   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%     7624.750000      0.000000      1.000000      0.000000      0.000000   \n",
       "50%    15249.500000      0.000000      1.000000      0.000000      0.000000   \n",
       "75%    22874.250000      0.000000      1.000000      0.000000      0.000000   \n",
       "max    30499.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "                  4             5             6             7             8  \\\n",
       "count  30500.000000  30500.000000  30500.000000  30500.000000  30500.000000   \n",
       "mean       0.437672      0.000623      0.000721      0.096431      0.003344   \n",
       "std        0.496108      0.024952      0.026848      0.023719      0.057734   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.090909      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.090909      0.000000   \n",
       "75%        1.000000      0.000000      0.000000      0.090909      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "           ...                336           337           338           339  \\\n",
       "count      ...       30500.000000  30500.000000  30500.000000  30500.000000   \n",
       "mean       ...           0.306157      0.489672      0.401607      0.050426   \n",
       "std        ...           0.128760      0.499902      0.490231      0.218826   \n",
       "min        ...           0.000000      0.000000      0.000000      0.000000   \n",
       "25%        ...           0.192617      0.000000      0.000000      0.000000   \n",
       "50%        ...           0.281274      0.000000      0.000000      0.000000   \n",
       "75%        ...           0.450414      1.000000      1.000000      0.000000   \n",
       "max        ...           1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "                340           341           342           343           344  \\\n",
       "count  30500.000000  30500.000000  30500.000000  30500.000000  30500.000000   \n",
       "mean       0.001246      0.085858      0.965934      0.985541      0.953803   \n",
       "std        0.035276      0.165875      0.181401      0.119375      0.209914   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      1.000000      1.000000      1.000000   \n",
       "50%        0.000000      0.000000      1.000000      1.000000      1.000000   \n",
       "75%        0.000000      0.111111      1.000000      1.000000      1.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "                345  \n",
       "count  30500.000000  \n",
       "mean       0.626230  \n",
       "std        0.483812  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        1.000000  \n",
       "75%        1.000000  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 347 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=train_df.drop(['0'], axis=1)\n",
    "Y=train_df['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X.drop(['Unnamed: 0'], axis=1)\n",
    "means=X.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>336</th>\n",
       "      <th>337</th>\n",
       "      <th>338</th>\n",
       "      <th>339</th>\n",
       "      <th>340</th>\n",
       "      <th>341</th>\n",
       "      <th>342</th>\n",
       "      <th>343</th>\n",
       "      <th>344</th>\n",
       "      <th>345</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.221395</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.241508</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.123067</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.296065</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.178956</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.450414</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.450414</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.334532</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.450414</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.450414</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.450414</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.220295</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.450414</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.193543</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.450414</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.172238</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.220295</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.221395</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.450414</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.450414</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.180948</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176697</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.123067</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.260746</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.315131</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.450414</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.450414</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.334532</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.211391</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.192617</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30470</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251900</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30471</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.450414</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30472</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.154625</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30473</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.155538</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30474</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.310009</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30475</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.450414</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30476</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.450414</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30477</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.165340</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30478</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.311360</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30479</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.241508</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30480</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.450414</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30481</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.310009</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30482</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.450414</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30483</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109160</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30484</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.334532</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30485</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.154625</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30486</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.450414</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30487</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.221395</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30488</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109160</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30489</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.475530</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30490</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166534</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30491</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.248978</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30492</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051827</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30493</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.450414</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30494</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.450414</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30495</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109160</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30496</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.450414</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30497</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176697</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30498</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.195690</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30499</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.172238</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30500 rows Ã— 345 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       1  2  3  4  5  6         7  8  9  10 ...        336  337  338  339  \\\n",
       "0      1  0  0  0  0  0  0.090909  0  0   1 ...   0.221395    0    1    0   \n",
       "1      1  0  0  1  0  0  0.090909  0  0   1 ...   0.241508    0    1    0   \n",
       "2      1  0  0  1  0  0  0.090909  0  0   1 ...   0.123067    0    1    0   \n",
       "3      1  0  0  1  0  0  0.136364  0  0   1 ...   0.296065    0    0    1   \n",
       "4      1  0  0  1  0  0  0.136364  0  0   1 ...   0.178956    0    0    1   \n",
       "5      1  0  0  0  0  0  0.090909  0  0   0 ...   0.450414    0    0    0   \n",
       "6      1  0  0  0  0  0  0.090909  0  0   1 ...   0.450414    1    0    0   \n",
       "7      1  0  0  1  0  0  0.090909  0  0   1 ...   0.334532    0    1    0   \n",
       "8      1  0  0  0  0  0  0.090909  0  0   1 ...   0.450414    1    0    0   \n",
       "9      1  0  0  0  0  0  0.136364  0  0   1 ...   0.450414    1    0    0   \n",
       "10     1  0  0  0  0  0  0.090909  0  0   1 ...   0.450414    1    0    0   \n",
       "11     1  0  0  0  0  0  0.090909  0  0   1 ...   0.220295    1    0    0   \n",
       "12     1  0  0  0  0  0  0.090909  0  0   1 ...   0.450414    1    0    0   \n",
       "13     1  0  0  1  0  0  0.136364  0  0   1 ...   0.193543    0    1    0   \n",
       "14     1  0  0  0  0  0  0.090909  0  0   1 ...   0.450414    1    0    0   \n",
       "15     1  0  0  1  0  0  0.090909  0  0   1 ...   0.172238    0    0    1   \n",
       "16     1  0  0  1  0  0  0.090909  0  0   1 ...   0.220295    0    1    0   \n",
       "17     1  0  0  1  0  0  0.090909  0  0   1 ...   0.221395    0    1    0   \n",
       "18     1  0  0  0  0  0  0.090909  0  0   1 ...   0.450414    1    0    0   \n",
       "19     1  0  0  0  0  0  0.136364  0  0   1 ...   0.450414    1    0    0   \n",
       "20     1  0  0  0  0  0  0.090909  0  0   1 ...   0.180948    0    1    0   \n",
       "21     1  0  0  1  0  0  0.090909  0  0   1 ...   0.176697    0    1    0   \n",
       "22     1  0  0  0  0  0  0.136364  0  0   0 ...   0.123067    0    0    0   \n",
       "23     1  0  0  1  0  0  0.090909  0  0   1 ...   0.260746    0    1    0   \n",
       "24     1  0  0  0  0  0  0.136364  0  0   1 ...   0.315131    1    0    0   \n",
       "25     1  0  0  0  0  0  0.045455  0  0   1 ...   0.450414    1    0    0   \n",
       "26     1  0  0  0  0  0  0.090909  0  0   0 ...   0.450414    0    0    0   \n",
       "27     1  0  0  1  0  0  0.090909  0  0   1 ...   0.334532    0    1    0   \n",
       "28     1  0  0  0  0  0  0.090909  0  0   1 ...   0.211391    1    0    0   \n",
       "29     1  0  0  1  0  0  0.090909  0  0   1 ...   0.192617    0    1    0   \n",
       "...   .. .. .. .. .. ..       ... .. ..  .. ...        ...  ...  ...  ...   \n",
       "30470  1  0  0  0  0  0  0.090909  0  0   1 ...   0.251900    1    0    0   \n",
       "30471  1  0  0  0  0  0  0.090909  0  0   1 ...   0.450414    1    0    0   \n",
       "30472  1  0  0  1  0  0  0.090909  0  0   1 ...   0.154625    0    1    0   \n",
       "30473  1  0  0  1  0  0  0.090909  0  0   1 ...   0.155538    0    1    0   \n",
       "30474  1  0  0  1  0  0  0.090909  0  0   1 ...   0.310009    0    1    0   \n",
       "30475  1  0  0  0  0  0  0.090909  0  0   1 ...   0.450414    1    0    0   \n",
       "30476  1  0  0  0  0  0  0.090909  0  0   1 ...   0.450414    1    0    0   \n",
       "30477  1  0  0  0  0  0  0.090909  0  0   1 ...   0.165340    1    0    0   \n",
       "30478  1  0  0  1  0  0  0.090909  0  0   1 ...   0.311360    0    1    0   \n",
       "30479  1  0  0  1  0  0  0.090909  0  0   1 ...   0.241508    0    1    0   \n",
       "30480  1  0  0  0  0  0  0.090909  0  0   1 ...   0.450414    1    0    0   \n",
       "30481  1  0  0  1  0  0  0.090909  0  0   1 ...   0.310009    0    1    0   \n",
       "30482  1  0  0  0  0  0  0.090909  0  0   1 ...   0.450414    1    0    0   \n",
       "30483  1  0  0  0  0  0  0.090909  0  0   1 ...   0.109160    1    0    0   \n",
       "30484  1  0  0  0  0  0  0.090909  0  0   1 ...   0.334532    1    0    0   \n",
       "30485  1  0  0  1  0  0  0.090909  0  0   1 ...   0.154625    0    1    0   \n",
       "30486  1  0  0  0  0  0  0.136364  0  0   1 ...   0.450414    1    0    0   \n",
       "30487  1  0  0  1  0  0  0.090909  0  0   1 ...   0.221395    0    1    0   \n",
       "30488  1  0  0  0  0  0  0.090909  0  0   1 ...   0.109160    1    0    0   \n",
       "30489  1  0  0  1  0  0  0.090909  0  0   1 ...   0.475530    0    1    0   \n",
       "30490  1  0  0  0  0  0  0.090909  0  0   1 ...   0.166534    0    1    0   \n",
       "30491  1  0  0  1  0  0  0.090909  0  0   1 ...   0.248978    0    1    0   \n",
       "30492  1  0  0  0  0  0  0.136364  0  0   1 ...   0.051827    1    0    0   \n",
       "30493  1  0  0  0  0  0  0.090909  0  0   0 ...   0.450414    0    0    0   \n",
       "30494  1  0  0  0  0  0  0.090909  0  0   1 ...   0.450414    1    0    0   \n",
       "30495  1  0  0  0  0  0  0.090909  0  0   1 ...   0.109160    1    0    0   \n",
       "30496  1  0  0  0  0  0  0.090909  0  0   1 ...   0.450414    1    0    0   \n",
       "30497  1  0  0  1  0  0  0.090909  0  0   1 ...   0.176697    0    1    0   \n",
       "30498  1  0  0  1  0  0  0.090909  0  0   1 ...   0.195690    0    1    0   \n",
       "30499  1  0  0  1  0  0  0.090909  0  0   1 ...   0.172238    0    0    1   \n",
       "\n",
       "       340       341  342  343  344  345  \n",
       "0        0  0.222222    1    1    1    1  \n",
       "1        0  0.111111    1    1    1    0  \n",
       "2        0  0.444444    1    1    1    1  \n",
       "3        0  0.222222    1    1    1    0  \n",
       "4        0  0.111111    1    1    1    1  \n",
       "5        0  0.000000    1    1    1    0  \n",
       "6        0  0.000000    1    1    1    0  \n",
       "7        0  0.000000    1    1    1    0  \n",
       "8        0  0.000000    1    1    1    1  \n",
       "9        0  0.000000    1    1    1    0  \n",
       "10       0  0.000000    1    1    1    0  \n",
       "11       0  0.222222    1    1    1    0  \n",
       "12       0  0.000000    1    1    1    1  \n",
       "13       0  0.111111    1    1    1    1  \n",
       "14       0  0.000000    1    1    1    1  \n",
       "15       0  0.000000    1    1    1    0  \n",
       "16       0  0.222222    1    1    1    1  \n",
       "17       0  0.222222    1    1    1    1  \n",
       "18       0  0.000000    1    1    1    1  \n",
       "19       0  0.000000    1    1    1    0  \n",
       "20       0  0.000000    1    1    1    0  \n",
       "21       0  0.000000    1    1    1    1  \n",
       "22       0  0.444444    0    1    0    1  \n",
       "23       0  0.222222    1    1    1    0  \n",
       "24       0  0.000000    1    1    1    0  \n",
       "25       0  0.000000    1    1    1    1  \n",
       "26       0  0.000000    1    1    1    0  \n",
       "27       0  0.000000    1    1    1    1  \n",
       "28       0  0.000000    1    0    1    1  \n",
       "29       0  0.000000    1    1    1    0  \n",
       "...    ...       ...  ...  ...  ...  ...  \n",
       "30470    0  0.000000    1    1    1    1  \n",
       "30471    0  0.000000    1    1    1    0  \n",
       "30472    0  0.444444    1    1    1    1  \n",
       "30473    0  0.222222    1    1    1    1  \n",
       "30474    0  0.000000    1    1    1    1  \n",
       "30475    0  0.000000    1    1    1    0  \n",
       "30476    0  0.000000    1    1    1    0  \n",
       "30477    0  0.000000    1    1    1    0  \n",
       "30478    0  0.000000    1    1    1    1  \n",
       "30479    0  0.111111    1    1    1    1  \n",
       "30480    0  0.000000    1    1    1    1  \n",
       "30481    0  0.000000    1    1    1    1  \n",
       "30482    0  0.000000    1    1    1    0  \n",
       "30483    0  0.000000    1    1    1    1  \n",
       "30484    0  0.000000    1    1    1    0  \n",
       "30485    0  0.444444    1    1    1    1  \n",
       "30486    0  0.000000    1    1    1    1  \n",
       "30487    0  0.222222    1    1    1    1  \n",
       "30488    0  0.000000    1    1    1    0  \n",
       "30489    0  0.000000    1    1    1    0  \n",
       "30490    0  0.666667    1    1    1    1  \n",
       "30491    0  0.333333    1    1    1    1  \n",
       "30492    0  0.000000    1    1    1    1  \n",
       "30493    0  0.000000    1    1    1    1  \n",
       "30494    0  0.000000    1    1    1    1  \n",
       "30495    0  0.000000    1    1    1    0  \n",
       "30496    0  0.000000    1    1    1    0  \n",
       "30497    0  0.000000    1    1    1    1  \n",
       "30498    0  0.000000    1    1    1    1  \n",
       "30499    0  0.000000    1    1    1    1  \n",
       "\n",
       "[30500 rows x 345 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled=StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.15032543, -0.14975425, -0.01280474, ...,  0.12112451,\n",
       "         0.22007777,  0.77256627],\n",
       "       [ 0.15032543, -0.14975425, -0.01280474, ...,  0.12112451,\n",
       "         0.22007777, -1.29438734],\n",
       "       [ 0.15032543, -0.14975425, -0.01280474, ...,  0.12112451,\n",
       "         0.22007777,  0.77256627],\n",
       "       ...,\n",
       "       [ 0.15032543, -0.14975425, -0.01280474, ...,  0.12112451,\n",
       "         0.22007777,  0.77256627],\n",
       "       [ 0.15032543, -0.14975425, -0.01280474, ...,  0.12112451,\n",
       "         0.22007777,  0.77256627],\n",
       "       [ 0.15032543, -0.14975425, -0.01280474, ...,  0.12112451,\n",
       "         0.22007777,  0.77256627]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## decomposition via PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca_scaled=pca.fit_transform(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30500L, 60L)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pca_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, \n",
    " X_test, \n",
    " y_train, y_test) = train_test_split(X_pca_scaled, Y, \n",
    "                                     test_size=0.3, \n",
    "                                     random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf=RandomForestClassifier(n_estimators = 1000,n_jobs=-1)\n",
    "rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test.csv',sep='\\t')\n",
    "X_val=test_df.drop(['Unnamed: 0'], axis=1)\n",
    "X_val=X_val.drop(['0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>336</th>\n",
       "      <th>337</th>\n",
       "      <th>338</th>\n",
       "      <th>339</th>\n",
       "      <th>340</th>\n",
       "      <th>341</th>\n",
       "      <th>342</th>\n",
       "      <th>343</th>\n",
       "      <th>344</th>\n",
       "      <th>345</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.192984</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.195690</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.192984</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.195690</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.289893</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.206963</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.450414</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.450414</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109160</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.134028</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.450414</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.220295</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.206963</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.220295</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.220295</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251114</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.450414</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.281274</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.310009</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.450414</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176697</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251114</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.450414</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.450414</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.327329</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.289893</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.241508</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.450414</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176697</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.475530</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4136</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.123067</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4137</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.450414</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4138</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.450414</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4139</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136817</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4140</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.450414</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4141</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.248978</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4142</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251114</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4143</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.450414</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.450414</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4145</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.450414</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4146</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.296065</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4147</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.207051</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4148</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.450414</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4149</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.172238</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4150</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.450414</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4151</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.244622</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4152</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.154625</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4153</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176697</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4154</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.220295</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4155</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.248978</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4156</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.220295</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4157</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.450414</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4158</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.475530</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4159</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.281274</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4160</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.450414</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4161</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.450414</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4162</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251114</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4163</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.450414</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4164</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.450414</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4165</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109160</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4166 rows Ã— 345 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      1  2  3  4  5  6         7  8  9  10 ...        336  337  338  339  340  \\\n",
       "0     1  0  0  1  0  0  0.136364  0  0   1 ...   0.192984    0    1    0    0   \n",
       "1     1  0  0  1  0  0  0.181818  0  0   1 ...   0.195690    0    1    0    0   \n",
       "2     1  0  0  0  0  0  0.090909  0  0   1 ...   0.192984    0    1    0    0   \n",
       "3     1  0  0  1  0  0  0.090909  0  0   1 ...   0.195690    0    1    0    0   \n",
       "4     1  0  0  1  0  0  0.090909  0  0   1 ...   0.289893    0    0    1    0   \n",
       "5     1  0  0  1  0  0  0.090909  0  0   1 ...   0.206963    0    1    0    0   \n",
       "6     1  0  0  0  0  0  0.181818  0  0   1 ...   0.450414    1    0    0    0   \n",
       "7     1  0  0  0  0  0  0.090909  0  0   1 ...   0.450414    1    0    0    0   \n",
       "8     1  0  0  0  0  0  0.090909  0  0   1 ...   0.109160    1    0    0    0   \n",
       "9     1  0  0  1  0  0  0.090909  0  0   1 ...   0.134028    0    1    0    0   \n",
       "10    1  0  0  0  0  0  0.090909  0  0   1 ...   0.450414    1    0    0    0   \n",
       "11    1  0  0  1  0  0  0.090909  0  0   1 ...   0.220295    0    1    0    0   \n",
       "12    1  0  0  1  0  0  0.090909  0  0   1 ...   0.206963    0    1    0    0   \n",
       "13    1  0  0  1  0  0  0.090909  0  0   1 ...   0.220295    0    1    0    0   \n",
       "14    1  0  0  1  0  0  0.090909  0  0   1 ...   0.220295    0    1    0    0   \n",
       "15    1  0  0  1  0  0  0.090909  0  0   1 ...   0.251114    0    1    0    0   \n",
       "16    1  0  0  0  0  0  0.090909  0  0   1 ...   0.450414    1    0    0    0   \n",
       "17    1  0  0  1  0  0  0.090909  0  0   1 ...   0.281274    0    1    0    0   \n",
       "18    1  0  0  1  0  0  0.136364  0  0   1 ...   0.310009    0    1    0    0   \n",
       "19    1  0  0  0  0  0  0.090909  0  0   1 ...   0.450414    1    0    0    0   \n",
       "20    0  1  0  1  0  0  0.090909  0  1   1 ...   0.176697    0    1    0    0   \n",
       "21    1  0  0  0  0  0  0.090909  0  0   1 ...   0.251114    1    0    0    0   \n",
       "22    1  0  0  0  0  0  0.136364  0  0   1 ...   0.450414    1    0    0    0   \n",
       "23    1  0  0  0  0  0  0.090909  0  0   0 ...   0.450414    0    0    0    0   \n",
       "24    1  0  0  1  0  0  0.090909  0  0   1 ...   0.327329    0    1    0    0   \n",
       "25    1  0  0  1  0  0  0.090909  0  0   1 ...   0.289893    0    0    1    0   \n",
       "26    1  0  0  1  0  0  0.090909  0  0   1 ...   0.241508    0    1    0    0   \n",
       "27    1  0  0  0  0  0  0.090909  0  0   1 ...   0.450414    1    0    0    0   \n",
       "28    1  0  0  0  0  0  0.090909  0  0   1 ...   0.176697    1    0    0    0   \n",
       "29    1  0  0  1  0  0  0.090909  0  0   1 ...   0.475530    0    1    0    0   \n",
       "...  .. .. .. .. .. ..       ... .. ..  .. ...        ...  ...  ...  ...  ...   \n",
       "4136  1  0  0  0  0  0  0.090909  0  0   1 ...   0.123067    1    0    0    0   \n",
       "4137  1  0  0  0  0  0  0.090909  0  0   1 ...   0.450414    1    0    0    0   \n",
       "4138  1  0  0  0  0  0  0.045455  0  0   1 ...   0.450414    1    0    0    0   \n",
       "4139  1  0  0  1  0  0  0.090909  0  0   1 ...   0.136817    0    1    0    0   \n",
       "4140  1  0  0  0  0  0  0.090909  0  0   1 ...   0.450414    1    0    0    0   \n",
       "4141  1  0  0  1  0  0  0.090909  0  0   1 ...   0.248978    0    1    0    0   \n",
       "4142  1  0  0  0  0  0  0.090909  0  0   1 ...   0.251114    1    0    0    0   \n",
       "4143  1  0  0  0  0  0  0.090909  0  0   1 ...   0.450414    1    0    0    0   \n",
       "4144  1  0  0  0  0  0  0.090909  0  0   1 ...   0.450414    1    0    0    0   \n",
       "4145  1  0  0  0  0  0  0.090909  0  0   0 ...   0.450414    0    0    0    0   \n",
       "4146  1  0  0  0  0  0  0.090909  0  0   1 ...   0.296065    1    0    0    0   \n",
       "4147  1  0  0  0  0  0  0.090909  0  0   1 ...   0.207051    1    0    0    0   \n",
       "4148  1  0  0  0  0  0  0.090909  0  0   1 ...   0.450414    1    0    0    0   \n",
       "4149  1  0  0  0  0  0  0.090909  0  0   1 ...   0.172238    1    0    0    0   \n",
       "4150  1  0  0  0  0  0  0.090909  0  0   0 ...   0.450414    0    0    0    0   \n",
       "4151  1  0  0  0  0  0  0.090909  0  0   1 ...   0.244622    1    0    0    0   \n",
       "4152  1  0  0  1  0  0  0.090909  0  0   1 ...   0.154625    0    1    0    0   \n",
       "4153  1  0  0  1  0  0  0.090909  0  0   1 ...   0.176697    0    1    0    0   \n",
       "4154  1  0  0  1  0  0  0.090909  0  0   1 ...   0.220295    0    1    0    0   \n",
       "4155  1  0  0  1  0  0  0.090909  0  0   1 ...   0.248978    0    1    0    0   \n",
       "4156  1  0  0  1  0  0  0.090909  0  0   1 ...   0.220295    0    1    0    0   \n",
       "4157  1  0  0  0  0  0  0.090909  0  0   1 ...   0.450414    1    0    0    0   \n",
       "4158  1  0  0  1  0  0  0.090909  0  0   1 ...   0.475530    0    1    0    0   \n",
       "4159  1  0  0  0  0  0  0.090909  0  0   1 ...   0.281274    0    1    0    0   \n",
       "4160  1  0  0  0  0  0  0.090909  0  0   1 ...   0.450414    1    0    0    0   \n",
       "4161  1  0  0  0  0  0  0.090909  0  0   1 ...   0.450414    1    0    0    0   \n",
       "4162  1  0  0  1  0  0  0.090909  0  0   1 ...   0.251114    0    1    0    0   \n",
       "4163  1  0  0  0  0  0  0.090909  0  0   1 ...   0.450414    1    0    0    0   \n",
       "4164  1  0  0  0  0  0  0.136364  0  0   1 ...   0.450414    1    0    0    0   \n",
       "4165  1  0  0  0  0  0  0.090909  0  0   0 ...   0.109160    0    0    0    0   \n",
       "\n",
       "           341  342  343  344  345  \n",
       "0     0.222222    1    1    1    1  \n",
       "1     0.000000    1    1    1    0  \n",
       "2     0.222222    1    1    1    0  \n",
       "3     0.000000    1    1    1    0  \n",
       "4     0.000000    1    1    1    1  \n",
       "5     0.000000    1    1    1    0  \n",
       "6     0.000000    1    1    1    0  \n",
       "7     0.000000    1    1    1    0  \n",
       "8     0.000000    1    1    1    1  \n",
       "9     0.111111    1    1    1    1  \n",
       "10    0.000000    1    1    1    1  \n",
       "11    0.222222    1    1    1    1  \n",
       "12    0.000000    0    0    0    1  \n",
       "13    0.222222    1    1    1    1  \n",
       "14    0.222222    1    1    1    1  \n",
       "15    0.000000    1    1    1    1  \n",
       "16    0.000000    0    1    0    0  \n",
       "17    0.000000    1    1    1    0  \n",
       "18    0.000000    1    1    1    1  \n",
       "19    0.000000    1    1    1    0  \n",
       "20    0.000000    1    1    1    0  \n",
       "21    0.000000    1    1    1    1  \n",
       "22    0.000000    1    1    1    1  \n",
       "23    0.000000    1    1    1    0  \n",
       "24    0.000000    1    1    1    1  \n",
       "25    0.000000    1    1    1    0  \n",
       "26    0.111111    1    1    1    1  \n",
       "27    0.000000    1    1    1    1  \n",
       "28    0.000000    1    1    1    1  \n",
       "29    0.000000    1    1    1    0  \n",
       "...        ...  ...  ...  ...  ...  \n",
       "4136  0.444444    1    1    1    0  \n",
       "4137  0.000000    1    1    1    0  \n",
       "4138  0.000000    1    1    1    1  \n",
       "4139  0.444444    1    1    1    1  \n",
       "4140  0.000000    1    1    1    1  \n",
       "4141  0.333333    1    1    1    0  \n",
       "4142  0.000000    1    1    1    1  \n",
       "4143  0.000000    1    1    1    1  \n",
       "4144  0.000000    1    1    1    1  \n",
       "4145  0.000000    1    1    1    1  \n",
       "4146  0.222222    0    1    0    1  \n",
       "4147  0.000000    1    1    1    1  \n",
       "4148  0.000000    1    1    1    1  \n",
       "4149  0.000000    1    1    1    1  \n",
       "4150  0.000000    1    1    1    1  \n",
       "4151  0.777778    1    1    1    1  \n",
       "4152  0.444444    1    1    1    1  \n",
       "4153  0.000000    1    1    1    0  \n",
       "4154  0.222222    1    1    1    0  \n",
       "4155  0.333333    1    1    1    0  \n",
       "4156  0.222222    1    1    1    1  \n",
       "4157  0.000000    1    1    1    1  \n",
       "4158  0.000000    1    1    1    0  \n",
       "4159  0.000000    1    1    1    1  \n",
       "4160  0.000000    1    1    0    0  \n",
       "4161  0.000000    0    0    0    1  \n",
       "4162  0.000000    1    1    1    1  \n",
       "4163  0.000000    1    1    1    0  \n",
       "4164  0.000000    1    1    1    1  \n",
       "4165  0.000000    1    1    1    0  \n",
       "\n",
       "[4166 rows x 345 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled=StandardScaler().fit_transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.528404965795529"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5131176993578411"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LogisticRegression\n",
    "\n",
    "LR=LogisticRegression()\n",
    "LR.fit(X_train,y_train)\n",
    "predictionsLR=LR.predict(X_test)\n",
    "roc_auc_score(y_test,predictionsLR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1\\Anaconda2\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5481399134987951"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SGDClassifier\n",
    "sgd=SGDClassifier()\n",
    "sgd.fit(X_train,y_train)\n",
    "predictionsSGD=sgd.predict(X_test)\n",
    "roc_auc_score(y_test,predictionsSGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.554583745305459"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree = DecisionTreeClassifier()\n",
    "decision_tree.fit(X_train, y_train)\n",
    "predictionsDT=decision_tree.predict(X_test)\n",
    "roc_auc_score(y_test,predictionsDT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1\\Anaconda2\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5135036805719122"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XGBoost\n",
    "gbm = xgb.XGBClassifier()\n",
    "gbm.fit(X_train, y_train)\n",
    "predictionsGBM=gbm.predict(X_test)\n",
    "roc_auc_score(y_test,predictionsGBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5009469966584963"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Linear SVC\n",
    "\n",
    "linear_svc = LinearSVC()\n",
    "linear_svc.fit(X_train, y_train)\n",
    "predictionsSVC=linear_svc.predict(X_test)\n",
    "roc_auc_score(y_test,predictionsSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.579538498471605"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#kNN\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "knn.fit(X_train, y_train)\n",
    "predictionsKNN=knn.predict(X_test)\n",
    "roc_auc_score(y_test,predictionsKNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1\\Anaconda2\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5002470215062392"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perceptron\n",
    "\n",
    "perceptron = Perceptron()\n",
    "perceptron.fit(X_train, y_train)\n",
    "predictionsPerc=perceptron.predict(X_test)\n",
    "roc_auc_score(y_test,predictionsPerc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6061094873082389"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gaussian Naive Bayes\n",
    "\n",
    "gaussian = GaussianNB()\n",
    "gaussian.fit(X_train, y_train)\n",
    "predictionsNB=gaussian.predict(X_test)\n",
    "roc_auc_score(y_test,predictionsNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaussian.fit(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4166L, 60L)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_pca=pca.fit_transform(X_test_scaled)\n",
    "X_test_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "predG=gaussian.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ñ‚ÑƒÑ‚ Ð³Ñ€ÐµÐ¹Ð´ÐµÑ€ Ð´Ð°Ð» 0.577\n",
    "submission = pd.DataFrame({\n",
    "        \"_ID_\": range(0,4166),\n",
    "        \"_VAL_\": predG\n",
    "    })\n",
    "submission.to_csv('submission_Gauss.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1\\Anaconda2\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.classifier import StackingClassifier\n",
    "from mlxtend.feature_selection import ColumnSelector\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import model_selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-fold cross validation:\n",
      "\n",
      "Accuracy: 0.57 (+/- 0.01) [KNN]\n",
      "Accuracy: 0.68 (+/- 0.01) [Random Forest]\n",
      "Accuracy: 0.63 (+/- 0.01) [Naive Bayes]\n",
      "Accuracy: 0.57 (+/- 0.01) [StackingClassifier]\n"
     ]
    }
   ],
   "source": [
    "clf1 = KNeighborsClassifier(n_neighbors=1)\n",
    "clf2 = RandomForestClassifier(random_state=1,n_estimators=500)\n",
    "clf3 = GaussianNB()\n",
    "lr = LogisticRegression()\n",
    "sclf = StackingClassifier(classifiers=[clf1, clf2, clf3],\n",
    "                          use_probas=True,\n",
    "                          average_probas=False,\n",
    "                          meta_classifier=clf3)\n",
    "\n",
    "print('3-fold cross validation:\\n')\n",
    "\n",
    "for clf, label in zip([clf1, clf2, clf3, sclf], \n",
    "                      ['KNN', \n",
    "                       'Random Forest', \n",
    "                       'Naive Bayes',\n",
    "                       'StackingClassifier']):\n",
    "\n",
    "    scores = model_selection.cross_val_score(clf, X_test, y_test, \n",
    "                                              cv=3, scoring='roc_auc')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" \n",
    "          % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingClassifier(average_probas=False,\n",
       "          classifiers=[KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
       "           weights='uniform'), RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto...\n",
       "            oob_score=False, random_state=1, verbose=0, warm_start=False), GaussianNB(priors=None)],\n",
       "          meta_classifier=GaussianNB(priors=None), refit=True,\n",
       "          store_train_meta_features=False, use_features_in_secondary=False,\n",
       "          use_probas=True, verbose=0)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sclf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=sclf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5799946875008088"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5282050191146439"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2.fit(X_train,y_train)\n",
    "predd=clf2.predict(X_test)\n",
    "roc_auc_score(y_test,predd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf22 = RandomForestClassifier(random_state=1,n_estimators=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=1,\n",
       "            oob_score=False, random_state=1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf22.fit(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5228004860908312"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predd2=clf22.predict(X_train)\n",
    "roc_auc_score(y_train,predd2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-84b0d4b86008>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mgrid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_pca_scaled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mpredGrid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_pca\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\1\\Anaconda2\\lib\\site-packages\\sklearn\\model_selection\\_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[1;32m--> 639\u001b[1;33m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[1;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\1\\Anaconda2\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    777\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\1\\Anaconda2\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.pyc\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    623\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 625\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\1\\Anaconda2\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.pyc\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\1\\Anaconda2\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.pyc\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\1\\Anaconda2\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\1\\Anaconda2\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\1\\Anaconda2\\lib\\site-packages\\sklearn\\model_selection\\_validation.pyc\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[0;32m    456\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 458\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    459\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\1\\Anaconda2\\lib\\site-packages\\sklearn\\svm\\base.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m         \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'i'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m         \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m         \u001b[1;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\1\\Anaconda2\\lib\\site-packages\\sklearn\\svm\\base.pyc\u001b[0m in \u001b[0;36m_dense_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    252\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 254\u001b[1;33m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32msklearn\\svm\\libsvm.pyx\u001b[0m in \u001b[0;36msklearn.svm.libsvm.fit\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "C_range = np.logspace(-2, 10, 13)\n",
    "gamma_range = np.logspace(-9, 3, 13)\n",
    "param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "cv = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "grid = GridSearchCV(SVC(), param_grid=param_grid, cv=cv)\n",
    "\n",
    "grid.fit(X_pca_scaled, Y)\n",
    "predGrid=grid.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "target = np.array([0] * 5 + [1] * 5)\n",
    "\n",
    "sss = model_selection.StratifiedShuffleSplit(n_splits = 4, test_size = 0.2)\n",
    "\n",
    "gaussian2 = GaussianNB()\n",
    "y_pred = cross_val_predict(gaussian2, X_train, y_train, cv=10, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# selecting features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectKBest(k=76, score_func=<function chi2 at 0x000000000BA137B8>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector=SelectKBest(chi2, k=76)\n",
    "selector.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new=selector.transform(X)\n",
    "X_v=selector.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, \n",
    " X_test, \n",
    " y_train, y_test) = train_test_split(X_new, Y, \n",
    "                                     test_size=0.3, \n",
    "                                     random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6516820433644879"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gaussian Naive Bayes\n",
    "\n",
    "gaussian = GaussianNB()\n",
    "gaussian.fit(X_train, y_train)\n",
    "predictionsNB=gaussian.predict(X_test)\n",
    "roc_auc_score(y_test,predictionsNB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ñ‚ÑƒÑ‚ Ð³Ñ€ÐµÐ¹Ð´ÐµÑ€ Ð´Ð°Ð» 0.655"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel trick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.kernel_approximation import RBFSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf_feature2 = RBFSampler(gamma=1, random_state=1)\n",
    "X_features2 = rbf_feature2.fit_transform(X)\n",
    "X__test_features2 = rbf_feature2.fit_transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train1, \n",
    " X_test1, \n",
    " y_train1, y_test1) = train_test_split(X_train, Y, \n",
    "                                     test_size=0.3, \n",
    "                                     random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian = GaussianNB()\n",
    "gaussian.fit(X_train, y_train)\n",
    "predictionsNB=gaussian.predict(X_test)\n",
    "roc_auc_score(y_test,predictionsNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SGDClassifier()   \n",
    "clf.fit(X_train, y_train)\n",
    "roc_auc_score(y_test,clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rocs=[]\n",
    "from sklearn import svm\n",
    "for kernel in ('linear', 'poly', 'rbf'):\n",
    "    clf = svm.SVC(kernel=kernel, gamma=2,class_weight='balanced')\n",
    "    clf.fit(X_train, y_train)\n",
    "    aa=roc_auc_score(y_test,clf.predict(X_test))\n",
    "    rocs.append(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', alpha=1e-05, batch_size='auto',\n",
       "       beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(5, 2), learning_rate='adaptive',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
       "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=1,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "scaler = StandardScaler()  \n",
    "# Don't cheat - fit only on training data\n",
    "scaler.fit(X)  \n",
    "X_train = scaler.transform(X)  \n",
    "# apply same transformation to test data\n",
    "X_test = scaler.transform(X_val)  \n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(5, 2), random_state=1,activation='logistic',learning_rate='adaptive',verbose=1)\n",
    "clf.fit(X_train, Y)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_to_file(pred):\n",
    "    pred = pd.DataFrame(pred, columns=[\"_VAL_\"])\n",
    "    pred.to_csv('solution_3.csv', index_label=\"_ID_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_to_file(clf.predict_proba(X_test)[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.71"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.55737350\n",
      "Iteration 2, loss = 0.46281635\n",
      "Iteration 3, loss = 0.43677414\n",
      "Iteration 4, loss = 0.42407547\n",
      "Iteration 5, loss = 0.41643490\n",
      "Iteration 6, loss = 0.40993514\n",
      "Iteration 7, loss = 0.40515015\n",
      "Iteration 8, loss = 0.39967223\n",
      "Iteration 9, loss = 0.39514767\n",
      "Iteration 10, loss = 0.39061411\n",
      "Iteration 11, loss = 0.38680415\n",
      "Iteration 12, loss = 0.38242702\n",
      "Iteration 13, loss = 0.37892208\n",
      "Iteration 14, loss = 0.37459316\n",
      "Iteration 15, loss = 0.37185026\n",
      "Iteration 16, loss = 0.36772447\n",
      "Iteration 17, loss = 0.36409786\n",
      "Iteration 18, loss = 0.36136189\n",
      "Iteration 19, loss = 0.35838605\n",
      "Iteration 20, loss = 0.35543673\n",
      "Iteration 21, loss = 0.35225547\n",
      "Iteration 22, loss = 0.34968615\n",
      "Iteration 23, loss = 0.34708562\n",
      "Iteration 24, loss = 0.34490166\n",
      "Iteration 25, loss = 0.34210891\n",
      "Iteration 26, loss = 0.33977462\n",
      "Iteration 27, loss = 0.33727277\n",
      "Iteration 28, loss = 0.33507849\n",
      "Iteration 29, loss = 0.33304085\n",
      "Iteration 30, loss = 0.33118543\n",
      "Iteration 31, loss = 0.32918540\n",
      "Iteration 32, loss = 0.32714073\n",
      "Iteration 33, loss = 0.32610385\n",
      "Iteration 34, loss = 0.32371770\n",
      "Iteration 35, loss = 0.32271982\n",
      "Iteration 36, loss = 0.32015816\n",
      "Iteration 37, loss = 0.31949127\n",
      "Iteration 38, loss = 0.31746211\n",
      "Iteration 39, loss = 0.31560783\n",
      "Iteration 40, loss = 0.31436619\n",
      "Iteration 41, loss = 0.31299873\n",
      "Iteration 42, loss = 0.31259203\n",
      "Iteration 43, loss = 0.31080585\n",
      "Iteration 44, loss = 0.30910861\n",
      "Iteration 45, loss = 0.30782794\n",
      "Iteration 46, loss = 0.30763146\n",
      "Iteration 47, loss = 0.30534151\n",
      "Iteration 48, loss = 0.30504915\n",
      "Iteration 49, loss = 0.30289231\n",
      "Iteration 50, loss = 0.30116036\n",
      "Iteration 51, loss = 0.30105005\n",
      "Iteration 52, loss = 0.29987521\n",
      "Iteration 53, loss = 0.29917073\n",
      "Iteration 54, loss = 0.29779663\n",
      "Iteration 55, loss = 0.29741028\n",
      "Iteration 56, loss = 0.29577356\n",
      "Iteration 57, loss = 0.29504014\n",
      "Iteration 58, loss = 0.29425998\n",
      "Iteration 59, loss = 0.29371432\n",
      "Iteration 60, loss = 0.29148617\n",
      "Iteration 61, loss = 0.29101890\n",
      "Iteration 62, loss = 0.29018589\n",
      "Iteration 63, loss = 0.28898597\n",
      "Iteration 64, loss = 0.28842949\n",
      "Iteration 65, loss = 0.28797323\n",
      "Iteration 66, loss = 0.28728742\n",
      "Iteration 67, loss = 0.28571092\n",
      "Iteration 68, loss = 0.28518117\n",
      "Iteration 69, loss = 0.28392024\n",
      "Iteration 70, loss = 0.28360505\n",
      "Iteration 71, loss = 0.28325769\n",
      "Iteration 72, loss = 0.28234168\n",
      "Iteration 73, loss = 0.28182068\n",
      "Iteration 74, loss = 0.28044387\n",
      "Iteration 75, loss = 0.28094421\n",
      "Iteration 76, loss = 0.27958216\n",
      "Iteration 77, loss = 0.27870453\n",
      "Iteration 78, loss = 0.27805347\n",
      "Iteration 79, loss = 0.27769106\n",
      "Iteration 80, loss = 0.27691968\n",
      "Iteration 81, loss = 0.27667092\n",
      "Iteration 82, loss = 0.27605209\n",
      "Iteration 83, loss = 0.27518864\n",
      "Iteration 84, loss = 0.27449957\n",
      "Iteration 85, loss = 0.27458568\n",
      "Iteration 86, loss = 0.27303843\n",
      "Iteration 87, loss = 0.27320165\n",
      "Iteration 88, loss = 0.27267660\n",
      "Iteration 89, loss = 0.27209697\n",
      "Iteration 90, loss = 0.27125669\n",
      "Iteration 91, loss = 0.27077224\n",
      "Iteration 92, loss = 0.26973425\n",
      "Iteration 93, loss = 0.26953588\n",
      "Iteration 94, loss = 0.26874828\n",
      "Iteration 95, loss = 0.26861890\n",
      "Iteration 96, loss = 0.26776260\n",
      "Iteration 97, loss = 0.26712421\n",
      "Iteration 98, loss = 0.26738737\n",
      "Iteration 99, loss = 0.26586634\n",
      "Iteration 100, loss = 0.26590151\n",
      "Iteration 101, loss = 0.26545199\n",
      "Iteration 102, loss = 0.26464425\n",
      "Iteration 103, loss = 0.26484539\n",
      "Iteration 104, loss = 0.26381601\n",
      "Iteration 105, loss = 0.26318565\n",
      "Iteration 106, loss = 0.26206815\n",
      "Iteration 107, loss = 0.26201360\n",
      "Iteration 108, loss = 0.26193001\n",
      "Iteration 109, loss = 0.26080590\n",
      "Iteration 110, loss = 0.26075312\n",
      "Iteration 111, loss = 0.26033466\n",
      "Iteration 112, loss = 0.26003734\n",
      "Iteration 113, loss = 0.25952446\n",
      "Iteration 114, loss = 0.25873806\n",
      "Iteration 115, loss = 0.25878743\n",
      "Iteration 116, loss = 0.25778257\n",
      "Iteration 117, loss = 0.25764460\n",
      "Iteration 118, loss = 0.25714054\n",
      "Iteration 119, loss = 0.25702086\n",
      "Iteration 120, loss = 0.25695818\n",
      "Iteration 121, loss = 0.25650878\n",
      "Iteration 122, loss = 0.25582905\n",
      "Iteration 123, loss = 0.25537939\n",
      "Iteration 124, loss = 0.25527529\n",
      "Iteration 125, loss = 0.25484077\n",
      "Iteration 126, loss = 0.25453650\n",
      "Iteration 127, loss = 0.25362300\n",
      "Iteration 128, loss = 0.25367309\n",
      "Iteration 129, loss = 0.25274179\n",
      "Iteration 130, loss = 0.25220820\n",
      "Iteration 131, loss = 0.25198532\n",
      "Iteration 132, loss = 0.25209571\n",
      "Iteration 133, loss = 0.25154432\n",
      "Iteration 134, loss = 0.25085915\n",
      "Iteration 135, loss = 0.25074031\n",
      "Iteration 136, loss = 0.25032660\n",
      "Iteration 137, loss = 0.25005532\n",
      "Iteration 138, loss = 0.24999515\n",
      "Iteration 139, loss = 0.24955497\n",
      "Iteration 140, loss = 0.24965374\n",
      "Iteration 141, loss = 0.24877175\n",
      "Iteration 142, loss = 0.24814110\n",
      "Iteration 143, loss = 0.24769221\n",
      "Iteration 144, loss = 0.24757846\n",
      "Iteration 145, loss = 0.24741974\n",
      "Iteration 146, loss = 0.24757007\n",
      "Iteration 147, loss = 0.24680850\n",
      "Iteration 148, loss = 0.24626492\n",
      "Iteration 149, loss = 0.24576224\n",
      "Iteration 150, loss = 0.24598385\n",
      "Iteration 151, loss = 0.24528751\n",
      "Iteration 152, loss = 0.24485614\n",
      "Iteration 153, loss = 0.24510940\n",
      "Iteration 154, loss = 0.24427022\n",
      "Iteration 155, loss = 0.24456141\n",
      "Iteration 156, loss = 0.24343059\n",
      "Iteration 157, loss = 0.24356007\n",
      "Iteration 158, loss = 0.24294653\n",
      "Iteration 159, loss = 0.24287972\n",
      "Iteration 160, loss = 0.24256892\n",
      "Iteration 161, loss = 0.24219039\n",
      "Iteration 162, loss = 0.24192604\n",
      "Iteration 163, loss = 0.24118810\n",
      "Iteration 164, loss = 0.24132783\n",
      "Iteration 165, loss = 0.24090743\n",
      "Iteration 166, loss = 0.24096342\n",
      "Iteration 167, loss = 0.24071339\n",
      "Iteration 168, loss = 0.24017571\n",
      "Iteration 169, loss = 0.24035407\n",
      "Iteration 170, loss = 0.24008738\n",
      "Iteration 171, loss = 0.23942351\n",
      "Iteration 172, loss = 0.23869729\n",
      "Iteration 173, loss = 0.23870284\n",
      "Iteration 174, loss = 0.23833127\n",
      "Iteration 175, loss = 0.23895654\n",
      "Iteration 176, loss = 0.23815461\n",
      "Iteration 177, loss = 0.23775783\n",
      "Iteration 178, loss = 0.23749412\n",
      "Iteration 179, loss = 0.23751244\n",
      "Iteration 180, loss = 0.23740894\n",
      "Iteration 181, loss = 0.23672859\n",
      "Iteration 182, loss = 0.23643462\n",
      "Iteration 183, loss = 0.23638010\n",
      "Iteration 184, loss = 0.23588368\n",
      "Iteration 185, loss = 0.23529893\n",
      "Iteration 186, loss = 0.23544419\n",
      "Iteration 187, loss = 0.23489792\n",
      "Iteration 188, loss = 0.23448799\n",
      "Iteration 189, loss = 0.23425618\n",
      "Iteration 190, loss = 0.23451560\n",
      "Iteration 191, loss = 0.23473353\n",
      "Iteration 192, loss = 0.23350092\n",
      "Iteration 193, loss = 0.23347711\n",
      "Iteration 194, loss = 0.23317213\n",
      "Iteration 195, loss = 0.23291081\n",
      "Iteration 196, loss = 0.23242116\n",
      "Iteration 197, loss = 0.23305498\n",
      "Iteration 198, loss = 0.23217681\n",
      "Iteration 199, loss = 0.23219651\n",
      "Iteration 200, loss = 0.23193644\n",
      "Iteration 201, loss = 0.23193331\n",
      "Iteration 202, loss = 0.23115021\n",
      "Iteration 203, loss = 0.23102419\n",
      "Iteration 204, loss = 0.23150272\n",
      "Iteration 205, loss = 0.23072370\n",
      "Iteration 206, loss = 0.23050620\n",
      "Iteration 207, loss = 0.22993606\n",
      "Iteration 208, loss = 0.22996938\n",
      "Iteration 209, loss = 0.23029746\n",
      "Iteration 210, loss = 0.22958979\n",
      "Iteration 211, loss = 0.22882816\n",
      "Iteration 212, loss = 0.22842331\n",
      "Iteration 213, loss = 0.22859919\n",
      "Iteration 214, loss = 0.22868612\n",
      "Iteration 215, loss = 0.22838564\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9029508196721312"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "scaler = StandardScaler()  \n",
    "# Don't cheat - fit only on training data\n",
    "scaler.fit(X)  \n",
    "X_train = scaler.transform(X)  \n",
    "# apply same transformation to test data\n",
    "X_test = scaler.transform(X_val)  \n",
    "clf = MLPClassifier(solver='adam', alpha=1e-5,hidden_layer_sizes=(20, 2),max_iter=1000, random_state=1,activation='tanh',learning_rate='adaptive',verbose=1)\n",
    "clf.fit(X_train, Y)\n",
    "clf.score(X_train,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_to_file(clf.predict_proba(X_test)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.55290602\n",
      "Iteration 2, loss = 0.45742578\n",
      "Iteration 3, loss = 0.43652019\n",
      "Iteration 4, loss = 0.42348949\n",
      "Iteration 5, loss = 0.41456246\n",
      "Iteration 6, loss = 0.40793537\n",
      "Iteration 7, loss = 0.40265242\n",
      "Iteration 8, loss = 0.39733411\n",
      "Iteration 9, loss = 0.39259261\n",
      "Iteration 10, loss = 0.38873653\n",
      "Iteration 11, loss = 0.38495465\n",
      "Iteration 12, loss = 0.38090446\n",
      "Iteration 13, loss = 0.37734290\n",
      "Iteration 14, loss = 0.37366362\n",
      "Iteration 15, loss = 0.37000687\n",
      "Iteration 16, loss = 0.36684833\n",
      "Iteration 17, loss = 0.36312146\n",
      "Iteration 18, loss = 0.36038531\n",
      "Iteration 19, loss = 0.35670666\n",
      "Iteration 20, loss = 0.35358227\n",
      "Iteration 21, loss = 0.35053837\n",
      "Iteration 22, loss = 0.34750279\n",
      "Iteration 23, loss = 0.34527016\n",
      "Iteration 24, loss = 0.34282861\n",
      "Iteration 25, loss = 0.33997883\n",
      "Iteration 26, loss = 0.33676013\n",
      "Iteration 27, loss = 0.33444237\n",
      "Iteration 28, loss = 0.33218771\n",
      "Iteration 29, loss = 0.32993587\n",
      "Iteration 30, loss = 0.32804871\n",
      "Iteration 31, loss = 0.32514008\n",
      "Iteration 32, loss = 0.32383064\n",
      "Iteration 33, loss = 0.32150064\n",
      "Iteration 34, loss = 0.31965225\n",
      "Iteration 35, loss = 0.31848083\n",
      "Iteration 36, loss = 0.31654933\n",
      "Iteration 37, loss = 0.31400186\n",
      "Iteration 38, loss = 0.31273579\n",
      "Iteration 39, loss = 0.31068105\n",
      "Iteration 40, loss = 0.30965483\n",
      "Iteration 41, loss = 0.30751075\n",
      "Iteration 42, loss = 0.30612960\n",
      "Iteration 43, loss = 0.30503755\n",
      "Iteration 44, loss = 0.30371257\n",
      "Iteration 45, loss = 0.30238874\n",
      "Iteration 46, loss = 0.30038328\n",
      "Iteration 47, loss = 0.29966114\n",
      "Iteration 48, loss = 0.29843028\n",
      "Iteration 49, loss = 0.29626759\n",
      "Iteration 50, loss = 0.29564276\n",
      "Iteration 51, loss = 0.29405300\n",
      "Iteration 52, loss = 0.29347798\n",
      "Iteration 53, loss = 0.29189590\n",
      "Iteration 54, loss = 0.29060097\n",
      "Iteration 55, loss = 0.28966888\n",
      "Iteration 56, loss = 0.28864414\n",
      "Iteration 57, loss = 0.28778966\n",
      "Iteration 58, loss = 0.28693277\n",
      "Iteration 59, loss = 0.28562921\n",
      "Iteration 60, loss = 0.28412370\n",
      "Iteration 61, loss = 0.28410236\n",
      "Iteration 62, loss = 0.28268774\n",
      "Iteration 63, loss = 0.28157659\n",
      "Iteration 64, loss = 0.28060904\n",
      "Iteration 65, loss = 0.27922710\n",
      "Iteration 66, loss = 0.27823045\n",
      "Iteration 67, loss = 0.27757394\n",
      "Iteration 68, loss = 0.27672902\n",
      "Iteration 69, loss = 0.27747694\n",
      "Iteration 70, loss = 0.27552697\n",
      "Iteration 71, loss = 0.27453223\n",
      "Iteration 72, loss = 0.27348573\n",
      "Iteration 73, loss = 0.27259104\n",
      "Iteration 74, loss = 0.27198209\n",
      "Iteration 75, loss = 0.27185824\n",
      "Iteration 76, loss = 0.27098862\n",
      "Iteration 77, loss = 0.27002697\n",
      "Iteration 78, loss = 0.26900470\n",
      "Iteration 79, loss = 0.26903587\n",
      "Iteration 80, loss = 0.26802486\n",
      "Iteration 81, loss = 0.26838075\n",
      "Iteration 82, loss = 0.26679312\n",
      "Iteration 83, loss = 0.26571335\n",
      "Iteration 84, loss = 0.26487545\n",
      "Iteration 85, loss = 0.26432341\n",
      "Iteration 86, loss = 0.26418627\n",
      "Iteration 87, loss = 0.26352111\n",
      "Iteration 88, loss = 0.26225412\n",
      "Iteration 89, loss = 0.26300467\n",
      "Iteration 90, loss = 0.26114639\n",
      "Iteration 91, loss = 0.26108285\n",
      "Iteration 92, loss = 0.26075875\n",
      "Iteration 93, loss = 0.25945164\n",
      "Iteration 94, loss = 0.25877071\n",
      "Iteration 95, loss = 0.25874648\n",
      "Iteration 96, loss = 0.25806317\n",
      "Iteration 97, loss = 0.25712223\n",
      "Iteration 98, loss = 0.25684012\n",
      "Iteration 99, loss = 0.25686317\n",
      "Iteration 100, loss = 0.25622745\n",
      "Iteration 101, loss = 0.25521463\n",
      "Iteration 102, loss = 0.25490362\n",
      "Iteration 103, loss = 0.25441226\n",
      "Iteration 104, loss = 0.25410237\n",
      "Iteration 105, loss = 0.25271877\n",
      "Iteration 106, loss = 0.25240343\n",
      "Iteration 107, loss = 0.25191188\n",
      "Iteration 108, loss = 0.25202064\n",
      "Iteration 109, loss = 0.25155909\n",
      "Iteration 110, loss = 0.25131186\n",
      "Iteration 111, loss = 0.25042813\n",
      "Iteration 112, loss = 0.24961789\n",
      "Iteration 113, loss = 0.24981251\n",
      "Iteration 114, loss = 0.24901277\n",
      "Iteration 115, loss = 0.24957074\n",
      "Iteration 116, loss = 0.24874963\n",
      "Iteration 117, loss = 0.24902225\n",
      "Iteration 118, loss = 0.24750278\n",
      "Iteration 119, loss = 0.24714791\n",
      "Iteration 120, loss = 0.24735732\n",
      "Iteration 121, loss = 0.24591785\n",
      "Iteration 122, loss = 0.24631911\n",
      "Iteration 123, loss = 0.24592527\n",
      "Iteration 124, loss = 0.24552073\n",
      "Iteration 125, loss = 0.24458213\n",
      "Iteration 126, loss = 0.24367241\n",
      "Iteration 127, loss = 0.24392325\n",
      "Iteration 128, loss = 0.24297857\n",
      "Iteration 129, loss = 0.24281180\n",
      "Iteration 130, loss = 0.24277806\n",
      "Iteration 131, loss = 0.24227607\n",
      "Iteration 132, loss = 0.24172163\n",
      "Iteration 133, loss = 0.24093601\n",
      "Iteration 134, loss = 0.24118876\n",
      "Iteration 135, loss = 0.24123154\n",
      "Iteration 136, loss = 0.24005488\n",
      "Iteration 137, loss = 0.23974742\n",
      "Iteration 138, loss = 0.24003145\n",
      "Iteration 139, loss = 0.23912736\n",
      "Iteration 140, loss = 0.23870348\n",
      "Iteration 141, loss = 0.23852119\n",
      "Iteration 142, loss = 0.23936218\n",
      "Iteration 143, loss = 0.23822428\n",
      "Iteration 144, loss = 0.23743383\n",
      "Iteration 145, loss = 0.23758086\n",
      "Iteration 146, loss = 0.23679251\n",
      "Iteration 147, loss = 0.23694466\n",
      "Iteration 148, loss = 0.23667878\n",
      "Iteration 149, loss = 0.23584973\n",
      "Iteration 150, loss = 0.23602996\n",
      "Iteration 151, loss = 0.23505961\n",
      "Iteration 152, loss = 0.23514137\n",
      "Iteration 153, loss = 0.23478010\n",
      "Iteration 154, loss = 0.23431251\n",
      "Iteration 155, loss = 0.23481518\n",
      "Iteration 156, loss = 0.23467221\n",
      "Iteration 157, loss = 0.23322919\n",
      "Iteration 158, loss = 0.23340139\n",
      "Iteration 159, loss = 0.23325049\n",
      "Iteration 160, loss = 0.23261652\n",
      "Iteration 161, loss = 0.23140482\n",
      "Iteration 162, loss = 0.23229707\n",
      "Iteration 163, loss = 0.23170925\n",
      "Iteration 164, loss = 0.23216328\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9131475409836065"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "scaler = StandardScaler()  \n",
    "# Don't cheat - fit only on training data\n",
    "scaler.fit(X)  \n",
    "X_train = scaler.transform(X)  \n",
    "# apply same transformation to test data\n",
    "X_test = scaler.transform(X_val)  \n",
    "clf = MLPClassifier(solver='adam', alpha=1e-5,hidden_layer_sizes=(20, 3),max_iter=1000, random_state=1,activation='tanh',learning_rate='adaptive',verbose=1)\n",
    "clf.fit(X_train, Y)\n",
    "clf.score(X_train,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.44918088\n",
      "Iteration 2, loss = 0.41801279\n",
      "Iteration 3, loss = 0.41002032\n",
      "Iteration 4, loss = 0.40472564\n",
      "Iteration 5, loss = 0.40004347\n",
      "Iteration 6, loss = 0.39535397\n",
      "Iteration 7, loss = 0.39074050\n",
      "Iteration 8, loss = 0.38651848\n",
      "Iteration 9, loss = 0.38240005\n",
      "Iteration 10, loss = 0.37860649\n",
      "Iteration 11, loss = 0.37421436\n",
      "Iteration 12, loss = 0.36983608\n",
      "Iteration 13, loss = 0.36651559\n",
      "Iteration 14, loss = 0.36228642\n",
      "Iteration 15, loss = 0.35887735\n",
      "Iteration 16, loss = 0.35504453\n",
      "Iteration 17, loss = 0.35256027\n",
      "Iteration 18, loss = 0.34872573\n",
      "Iteration 19, loss = 0.34519472\n",
      "Iteration 20, loss = 0.34196111\n",
      "Iteration 21, loss = 0.33897202\n",
      "Iteration 22, loss = 0.33544085\n",
      "Iteration 23, loss = 0.33389416\n",
      "Iteration 24, loss = 0.33050820\n",
      "Iteration 25, loss = 0.32732800\n",
      "Iteration 26, loss = 0.32456596\n",
      "Iteration 27, loss = 0.32265957\n",
      "Iteration 28, loss = 0.31979498\n",
      "Iteration 29, loss = 0.31759744\n",
      "Iteration 30, loss = 0.31492556\n",
      "Iteration 31, loss = 0.31310553\n",
      "Iteration 32, loss = 0.31149495\n",
      "Iteration 33, loss = 0.30943291\n",
      "Iteration 34, loss = 0.30727701\n",
      "Iteration 35, loss = 0.30585799\n",
      "Iteration 36, loss = 0.30419131\n",
      "Iteration 37, loss = 0.30220503\n",
      "Iteration 38, loss = 0.30079223\n",
      "Iteration 39, loss = 0.29896750\n",
      "Iteration 40, loss = 0.29769521\n",
      "Iteration 41, loss = 0.29593390\n",
      "Iteration 42, loss = 0.29534102\n",
      "Iteration 43, loss = 0.29328865\n",
      "Iteration 44, loss = 0.29159036\n",
      "Iteration 45, loss = 0.29074365\n",
      "Iteration 46, loss = 0.28918997\n",
      "Iteration 47, loss = 0.28840869\n",
      "Iteration 48, loss = 0.28672120\n",
      "Iteration 49, loss = 0.28530071\n",
      "Iteration 50, loss = 0.28465029\n",
      "Iteration 51, loss = 0.28324065\n",
      "Iteration 52, loss = 0.28188015\n",
      "Iteration 53, loss = 0.28081377\n",
      "Iteration 54, loss = 0.27999382\n",
      "Iteration 55, loss = 0.27893856\n",
      "Iteration 56, loss = 0.27728261\n",
      "Iteration 57, loss = 0.27632040\n",
      "Iteration 58, loss = 0.27568193\n",
      "Iteration 59, loss = 0.27475719\n",
      "Iteration 60, loss = 0.27381237\n",
      "Iteration 61, loss = 0.27305999\n",
      "Iteration 62, loss = 0.27180111\n",
      "Iteration 63, loss = 0.27195067\n",
      "Iteration 64, loss = 0.27000672\n",
      "Iteration 65, loss = 0.26957139\n",
      "Iteration 66, loss = 0.26835667\n",
      "Iteration 67, loss = 0.26798633\n",
      "Iteration 68, loss = 0.26760858\n",
      "Iteration 69, loss = 0.26678782\n",
      "Iteration 70, loss = 0.26513211\n",
      "Iteration 71, loss = 0.26521272\n",
      "Iteration 72, loss = 0.26389691\n",
      "Iteration 73, loss = 0.26318445\n",
      "Iteration 74, loss = 0.26240538\n",
      "Iteration 75, loss = 0.26219494\n",
      "Iteration 76, loss = 0.26136696\n",
      "Iteration 77, loss = 0.26039540\n",
      "Iteration 78, loss = 0.25910903\n",
      "Iteration 79, loss = 0.25865777\n",
      "Iteration 80, loss = 0.25856001\n",
      "Iteration 81, loss = 0.25809456\n",
      "Iteration 82, loss = 0.25710505\n",
      "Iteration 83, loss = 0.25701803\n",
      "Iteration 84, loss = 0.25578020\n",
      "Iteration 85, loss = 0.25463100\n",
      "Iteration 86, loss = 0.25467858\n",
      "Iteration 87, loss = 0.25417336\n",
      "Iteration 88, loss = 0.25274903\n",
      "Iteration 89, loss = 0.25340777\n",
      "Iteration 90, loss = 0.25182879\n",
      "Iteration 91, loss = 0.25160752\n",
      "Iteration 92, loss = 0.25069891\n",
      "Iteration 93, loss = 0.25081396\n",
      "Iteration 94, loss = 0.24904950\n",
      "Iteration 95, loss = 0.24885539\n",
      "Iteration 96, loss = 0.24859469\n",
      "Iteration 97, loss = 0.24799619\n",
      "Iteration 98, loss = 0.24764206\n",
      "Iteration 99, loss = 0.24658348\n",
      "Iteration 100, loss = 0.24632202\n",
      "Iteration 101, loss = 0.24537615\n",
      "Iteration 102, loss = 0.24453508\n",
      "Iteration 103, loss = 0.24416085\n",
      "Iteration 104, loss = 0.24391849\n",
      "Iteration 105, loss = 0.24385415\n",
      "Iteration 106, loss = 0.24285320\n",
      "Iteration 107, loss = 0.24271463\n",
      "Iteration 108, loss = 0.24243327\n",
      "Iteration 109, loss = 0.24147131\n",
      "Iteration 110, loss = 0.24088982\n",
      "Iteration 111, loss = 0.24073171\n",
      "Iteration 112, loss = 0.24009827\n",
      "Iteration 113, loss = 0.24050709\n",
      "Iteration 114, loss = 0.23953487\n",
      "Iteration 115, loss = 0.23857160\n",
      "Iteration 116, loss = 0.23774538\n",
      "Iteration 117, loss = 0.23782377\n",
      "Iteration 118, loss = 0.23788697\n",
      "Iteration 119, loss = 0.23717974\n",
      "Iteration 120, loss = 0.23676394\n",
      "Iteration 121, loss = 0.23633220\n",
      "Iteration 122, loss = 0.23557917\n",
      "Iteration 123, loss = 0.23504793\n",
      "Iteration 124, loss = 0.23461018\n",
      "Iteration 125, loss = 0.23445171\n",
      "Iteration 126, loss = 0.23423916\n",
      "Iteration 127, loss = 0.23375300\n",
      "Iteration 128, loss = 0.23349436\n",
      "Iteration 129, loss = 0.23287344\n",
      "Iteration 130, loss = 0.23201363\n",
      "Iteration 131, loss = 0.23192541\n",
      "Iteration 132, loss = 0.23093225\n",
      "Iteration 133, loss = 0.23172941\n",
      "Iteration 134, loss = 0.23055391\n",
      "Iteration 135, loss = 0.23061850\n",
      "Iteration 136, loss = 0.22962733\n",
      "Iteration 137, loss = 0.22945405\n",
      "Iteration 138, loss = 0.22912689\n",
      "Iteration 139, loss = 0.22903481\n",
      "Iteration 140, loss = 0.22871490\n",
      "Iteration 141, loss = 0.22743276\n",
      "Iteration 142, loss = 0.22747805\n",
      "Iteration 143, loss = 0.22694014\n",
      "Iteration 144, loss = 0.22698024\n",
      "Iteration 145, loss = 0.22631857\n",
      "Iteration 146, loss = 0.22635513\n",
      "Iteration 147, loss = 0.22569033\n",
      "Iteration 148, loss = 0.22517192\n",
      "Iteration 149, loss = 0.22526231\n",
      "Iteration 150, loss = 0.22490521\n",
      "Iteration 151, loss = 0.22431059\n",
      "Iteration 152, loss = 0.22448730\n",
      "Iteration 153, loss = 0.22389480\n",
      "Iteration 154, loss = 0.22347331\n",
      "Iteration 155, loss = 0.22339269\n",
      "Iteration 156, loss = 0.22270659\n",
      "Iteration 157, loss = 0.22265263\n",
      "Iteration 158, loss = 0.22178165\n",
      "Iteration 159, loss = 0.22214096\n",
      "Iteration 160, loss = 0.22164959\n",
      "Iteration 161, loss = 0.22130850\n",
      "Iteration 162, loss = 0.22068198\n",
      "Iteration 163, loss = 0.22060528\n",
      "Iteration 164, loss = 0.21991826\n",
      "Iteration 165, loss = 0.22043551\n",
      "Iteration 166, loss = 0.22002548\n",
      "Iteration 167, loss = 0.21944183\n",
      "Iteration 168, loss = 0.21918476\n",
      "Iteration 169, loss = 0.21935342\n",
      "Iteration 170, loss = 0.21848620\n",
      "Iteration 171, loss = 0.21843351\n",
      "Iteration 172, loss = 0.21790734\n",
      "Iteration 173, loss = 0.21714325\n",
      "Iteration 174, loss = 0.21789020\n",
      "Iteration 175, loss = 0.21720847\n",
      "Iteration 176, loss = 0.21745547\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9217704918032786"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "scaler = StandardScaler()  \n",
    "# Don't cheat - fit only on training data\n",
    "scaler.fit(X)  \n",
    "X_train = scaler.transform(X)  \n",
    "# apply same transformation to test data\n",
    "X_test = scaler.transform(X_val)  \n",
    "clf = MLPClassifier(solver='adam', alpha=1e-5,hidden_layer_sizes=(20, 4),max_iter=1000, random_state=1,activation='tanh',learning_rate='adaptive',verbose=1)\n",
    "clf.fit(X_train, Y)\n",
    "clf.score(X_train,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_to_file(clf.predict_proba(X_test)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.52412011\n",
      "Iteration 2, loss = 0.43114090\n",
      "Iteration 3, loss = 0.41715752\n",
      "Iteration 4, loss = 0.40873224\n",
      "Iteration 5, loss = 0.40177321\n",
      "Iteration 6, loss = 0.39493473\n",
      "Iteration 7, loss = 0.38879794\n",
      "Iteration 8, loss = 0.38315853\n",
      "Iteration 9, loss = 0.37665978\n",
      "Iteration 10, loss = 0.37157007\n",
      "Iteration 11, loss = 0.36631747\n",
      "Iteration 12, loss = 0.36050703\n",
      "Iteration 13, loss = 0.35455883\n",
      "Iteration 14, loss = 0.34929997\n",
      "Iteration 15, loss = 0.34397375\n",
      "Iteration 16, loss = 0.33896135\n",
      "Iteration 17, loss = 0.33371374\n",
      "Iteration 18, loss = 0.32821903\n",
      "Iteration 19, loss = 0.32485055\n",
      "Iteration 20, loss = 0.31951396\n",
      "Iteration 21, loss = 0.31558595\n",
      "Iteration 22, loss = 0.31024704\n",
      "Iteration 23, loss = 0.30595701\n",
      "Iteration 24, loss = 0.30197478\n",
      "Iteration 25, loss = 0.29809109\n",
      "Iteration 26, loss = 0.29474836\n",
      "Iteration 27, loss = 0.29128934\n",
      "Iteration 28, loss = 0.28713526\n",
      "Iteration 29, loss = 0.28384205\n",
      "Iteration 30, loss = 0.28186749\n",
      "Iteration 31, loss = 0.27844527\n",
      "Iteration 32, loss = 0.27471518\n",
      "Iteration 33, loss = 0.27203243\n",
      "Iteration 34, loss = 0.27014676\n",
      "Iteration 35, loss = 0.26685857\n",
      "Iteration 36, loss = 0.26342836\n",
      "Iteration 37, loss = 0.26142644\n",
      "Iteration 38, loss = 0.25949122\n",
      "Iteration 39, loss = 0.25710459\n",
      "Iteration 40, loss = 0.25475699\n",
      "Iteration 41, loss = 0.25225663\n",
      "Iteration 42, loss = 0.24967727\n",
      "Iteration 43, loss = 0.24770261\n",
      "Iteration 44, loss = 0.24589312\n",
      "Iteration 45, loss = 0.24447577\n",
      "Iteration 46, loss = 0.24170259\n",
      "Iteration 47, loss = 0.24016377\n",
      "Iteration 48, loss = 0.23786830\n",
      "Iteration 49, loss = 0.23693667\n",
      "Iteration 50, loss = 0.23552573\n",
      "Iteration 51, loss = 0.23297531\n",
      "Iteration 52, loss = 0.23210453\n",
      "Iteration 53, loss = 0.22980441\n",
      "Iteration 54, loss = 0.22798060\n",
      "Iteration 55, loss = 0.22737310\n",
      "Iteration 56, loss = 0.22467819\n",
      "Iteration 57, loss = 0.22328456\n",
      "Iteration 58, loss = 0.22189054\n",
      "Iteration 59, loss = 0.22021213\n",
      "Iteration 60, loss = 0.21932679\n",
      "Iteration 61, loss = 0.21762778\n",
      "Iteration 62, loss = 0.21603306\n",
      "Iteration 63, loss = 0.21565724\n",
      "Iteration 64, loss = 0.21376336\n",
      "Iteration 65, loss = 0.21264308\n",
      "Iteration 66, loss = 0.21075815\n",
      "Iteration 67, loss = 0.20943472\n",
      "Iteration 68, loss = 0.20937910\n",
      "Iteration 69, loss = 0.20761014\n",
      "Iteration 70, loss = 0.20656563\n",
      "Iteration 71, loss = 0.20509768\n",
      "Iteration 72, loss = 0.20359378\n",
      "Iteration 73, loss = 0.20258272\n",
      "Iteration 74, loss = 0.20134681\n",
      "Iteration 75, loss = 0.20095936\n",
      "Iteration 76, loss = 0.20027522\n",
      "Iteration 77, loss = 0.19922882\n",
      "Iteration 78, loss = 0.19693423\n",
      "Iteration 79, loss = 0.19628287\n",
      "Iteration 80, loss = 0.19537824\n",
      "Iteration 81, loss = 0.19363169\n",
      "Iteration 82, loss = 0.19350860\n",
      "Iteration 83, loss = 0.19302279\n",
      "Iteration 84, loss = 0.19216569\n",
      "Iteration 85, loss = 0.18961596\n",
      "Iteration 86, loss = 0.18864055\n",
      "Iteration 87, loss = 0.18858832\n",
      "Iteration 88, loss = 0.18788039\n",
      "Iteration 89, loss = 0.18817448\n",
      "Iteration 90, loss = 0.18598786\n",
      "Iteration 91, loss = 0.18560679\n",
      "Iteration 92, loss = 0.18434528\n",
      "Iteration 93, loss = 0.18349974\n",
      "Iteration 94, loss = 0.18306805\n",
      "Iteration 95, loss = 0.18198658\n",
      "Iteration 96, loss = 0.18147093\n",
      "Iteration 97, loss = 0.18087684\n",
      "Iteration 98, loss = 0.17995872\n",
      "Iteration 99, loss = 0.17880053\n",
      "Iteration 100, loss = 0.17793556\n",
      "Iteration 101, loss = 0.17686118\n",
      "Iteration 102, loss = 0.17708114\n",
      "Iteration 103, loss = 0.17628318\n",
      "Iteration 104, loss = 0.17537244\n",
      "Iteration 105, loss = 0.17461569\n",
      "Iteration 106, loss = 0.17457881\n",
      "Iteration 107, loss = 0.17356348\n",
      "Iteration 108, loss = 0.17217431\n",
      "Iteration 109, loss = 0.17160136\n",
      "Iteration 110, loss = 0.17144028\n",
      "Iteration 111, loss = 0.16949223\n",
      "Iteration 112, loss = 0.16908190\n",
      "Iteration 113, loss = 0.16935933\n",
      "Iteration 114, loss = 0.16796817\n",
      "Iteration 115, loss = 0.16774500\n",
      "Iteration 116, loss = 0.16693023\n",
      "Iteration 117, loss = 0.16575444\n",
      "Iteration 118, loss = 0.16623256\n",
      "Iteration 119, loss = 0.16568396\n",
      "Iteration 120, loss = 0.16490851\n",
      "Iteration 121, loss = 0.16403836\n",
      "Iteration 122, loss = 0.16371715\n",
      "Iteration 123, loss = 0.16345214\n",
      "Iteration 124, loss = 0.16308022\n",
      "Iteration 125, loss = 0.16193666\n",
      "Iteration 126, loss = 0.16270268\n",
      "Iteration 127, loss = 0.16215942\n",
      "Iteration 128, loss = 0.16003525\n",
      "Iteration 129, loss = 0.15964223\n",
      "Iteration 130, loss = 0.15955231\n",
      "Iteration 131, loss = 0.15873763\n",
      "Iteration 132, loss = 0.15785965\n",
      "Iteration 133, loss = 0.15663733\n",
      "Iteration 134, loss = 0.15752112\n",
      "Iteration 135, loss = 0.15637434\n",
      "Iteration 136, loss = 0.15560128\n",
      "Iteration 137, loss = 0.15547302\n",
      "Iteration 138, loss = 0.15501889\n",
      "Iteration 139, loss = 0.15448356\n",
      "Iteration 140, loss = 0.15403511\n",
      "Iteration 141, loss = 0.15452287\n",
      "Iteration 142, loss = 0.15423813\n",
      "Iteration 143, loss = 0.15327762\n",
      "Iteration 144, loss = 0.15254308\n",
      "Iteration 145, loss = 0.15150236\n",
      "Iteration 146, loss = 0.15078876\n",
      "Iteration 147, loss = 0.15021402\n",
      "Iteration 148, loss = 0.15126873\n",
      "Iteration 149, loss = 0.15024164\n",
      "Iteration 150, loss = 0.15004153\n",
      "Iteration 151, loss = 0.14952526\n",
      "Iteration 152, loss = 0.15025134\n",
      "Iteration 153, loss = 0.14896761\n",
      "Iteration 154, loss = 0.14847572\n",
      "Iteration 155, loss = 0.14876426\n",
      "Iteration 156, loss = 0.14784319\n",
      "Iteration 157, loss = 0.14782976\n",
      "Iteration 158, loss = 0.14721679\n",
      "Iteration 159, loss = 0.14615396\n",
      "Iteration 160, loss = 0.14542676\n",
      "Iteration 161, loss = 0.14468082\n",
      "Iteration 162, loss = 0.14546875\n",
      "Iteration 163, loss = 0.14410721\n",
      "Iteration 164, loss = 0.14441008\n",
      "Iteration 165, loss = 0.14374500\n",
      "Iteration 166, loss = 0.14374333\n",
      "Iteration 167, loss = 0.14456722\n",
      "Iteration 168, loss = 0.14390967\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9534754098360656"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "scaler = StandardScaler()  \n",
    "# Don't cheat - fit only on training data\n",
    "scaler.fit(X)  \n",
    "X_train = scaler.transform(X)  \n",
    "# apply same transformation to test data\n",
    "X_test = scaler.transform(X_val)  \n",
    "clf = MLPClassifier(solver='adam', alpha=1e-5,hidden_layer_sizes=(30, 4),max_iter=1000, random_state=1,activation='tanh',learning_rate='adaptive',verbose=1)\n",
    "clf.fit(X_train, Y)\n",
    "clf.score(X_train,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.63"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 1 adam 0.5\n",
      "2 2 adam 0.5868023381467208\n",
      "2 3 adam 0.5828213609057001\n",
      "3 1 adam 0.5740775760768002\n",
      "3 2 adam 0.5602606295279188\n",
      "3 3 adam 0.5570157019616776\n",
      "4 1 adam 0.5831525832593509\n",
      "4 2 adam 0.5731224909603394\n",
      "4 3 adam 0.5680574176983225\n",
      "5 1 adam 0.589351820097165\n",
      "5 2 adam 0.5551057743824948\n",
      "5 3 adam 0.5688183798236328\n",
      "6 1 adam 0.6064204076323984\n",
      "6 2 adam 0.564286255056904\n",
      "6 3 adam 0.5646383456321032\n",
      "7 1 adam 0.5772098314235946\n",
      "7 2 adam 0.5728170707875958\n",
      "7 3 adam 0.5714553788892541\n",
      "8 1 adam 0.5971521671890733\n",
      "8 2 adam 0.5774685811938823\n",
      "8 3 adam 0.5675488963460875\n",
      "9 1 adam 0.5992400408434774\n",
      "9 2 adam 0.593076959412765\n",
      "9 3 adam 0.5626568351999337\n",
      "10 1 adam 0.5999395306882567\n",
      "10 2 adam 0.6010905182566203\n",
      "10 3 adam 0.5668554728447818\n",
      "11 1 adam 0.5653761747676347\n",
      "11 2 adam 0.5628118909391152\n",
      "11 3 adam 0.5821018925697484\n",
      "12 1 adam 0.5803252627778224\n",
      "12 2 adam 0.5705826342748729\n",
      "12 3 adam 0.5675755882573708\n",
      "13 1 adam 0.5945937070502881\n",
      "13 2 adam 0.5924389418485168\n",
      "13 3 adam 0.5679864819219729\n",
      "14 1 adam 0.5853555556705914\n",
      "14 2 adam 0.5924739648715035\n",
      "14 3 adam 0.5712482334807806\n",
      "15 1 adam 0.5975100814540072\n",
      "15 2 adam 0.5613334825923443\n",
      "15 3 adam 0.5723224615830601\n",
      "16 1 adam 0.5856676892634456\n",
      "16 2 adam 0.5827226008339524\n",
      "16 3 adam 0.5574837810240894\n",
      "17 1 adam 0.5928628579304418\n",
      "17 2 adam 0.5883208652449962\n",
      "17 3 adam 0.5642182311254216\n",
      "18 1 adam 0.5895034786840014\n",
      "18 2 adam 0.5645546300921697\n",
      "18 3 adam 0.5776164382054753\n",
      "19 1 adam 0.5899024823153955\n",
      "19 2 adam 0.5934577640137387\n",
      "19 3 adam 0.5855027656055471\n",
      "2 1 sgd 0.5\n",
      "2 2 sgd 0.5179929365114287\n",
      "2 3 sgd 0.5566586774271197\n",
      "3 1 sgd 0.5730839090158483\n",
      "3 2 sgd 0.5610027455461715\n",
      "3 3 sgd 0.5670756406705785\n",
      "4 1 sgd 0.5711650032483246\n",
      "4 2 sgd 0.5633592368895802\n",
      "4 3 sgd 0.570794956296444\n",
      "5 1 sgd 0.5861677177348177\n",
      "5 2 sgd 0.583067088258665\n",
      "5 3 sgd 0.5717210847333914\n",
      "6 1 sgd 0.5863357958913221\n",
      "6 2 sgd 0.575789579089589\n",
      "6 3 sgd 0.571539984159564\n",
      "7 1 sgd 0.5785926341972237\n",
      "7 2 sgd 0.5892503908342889\n",
      "7 3 sgd 0.576012416106514\n",
      "8 1 sgd 0.5836449276956566\n",
      "8 2 sgd 0.5712415200606699\n",
      "8 3 sgd 0.5730877105910916\n",
      "9 1 sgd 0.585351754095348\n",
      "9 2 sgd 0.5868359861318535\n",
      "9 3 sgd 0.5776595496864266\n",
      "10 1 sgd 0.6003993595235445\n",
      "10 2 sgd 0.5847858046915645\n",
      "10 3 sgd 0.586853942508535\n",
      "11 1 sgd 0.5848892560689318\n",
      "11 2 sgd 0.5745687881289909\n",
      "11 3 sgd 0.576159383387731\n",
      "12 1 sgd 0.5869075689848403\n",
      "12 2 sgd 0.5852572809063215\n",
      "12 3 sgd 0.5742395878898313\n",
      "13 1 sgd 0.5854184029889764\n",
      "13 2 sgd 0.5741848290294109\n",
      "13 3 sgd 0.5743030822848536\n",
      "14 1 sgd 0.5889974647537356\n",
      "14 2 sgd 0.5873373087564998\n",
      "14 3 sgd 0.5752402110246329\n",
      "15 1 sgd 0.5901841224217231\n",
      "15 2 sgd 0.5730080392801402\n",
      "15 3 sgd 0.5787326454045911\n",
      "16 1 sgd 0.5922282375185388\n",
      "16 2 sgd 0.578582523624768\n",
      "16 3 sgd 0.5755166745178633\n",
      "17 1 sgd 0.58106624641196\n",
      "17 2 sgd 0.5885199221955052\n",
      "17 3 sgd 0.5813438422893054\n",
      "18 1 sgd 0.5921676549683837\n",
      "18 2 sgd 0.5690966227776153\n",
      "18 3 sgd 0.5756230377400978\n",
      "19 1 sgd 0.5822659264972707\n",
      "19 2 sgd 0.5953627576335632\n",
      "19 3 sgd 0.5768227178254084\n",
      "2 1 lbfgs 0.5\n",
      "2 2 lbfgs 0.5039928672742284\n",
      "2 3 lbfgs 0.4993314889492252\n",
      "3 1 lbfgs 0.6066921798200091\n",
      "3 2 lbfgs 0.5844308022714978\n",
      "3 3 lbfgs 0.571775600940073\n",
      "4 1 lbfgs 0.5494168383576677\n",
      "4 2 lbfgs 0.5872529461399291\n",
      "4 3 lbfgs 0.5669044080154677\n",
      "5 1 lbfgs 0.6117343627459861\n",
      "5 2 lbfgs 0.5540761945681799\n",
      "5 3 lbfgs 0.5954276270664394\n",
      "6 1 lbfgs 0.6305717342689199\n",
      "6 2 lbfgs 0.565417264134095\n",
      "6 3 lbfgs 0.5857556916861005\n",
      "7 1 lbfgs 0.6081492346377536\n",
      "7 2 lbfgs 0.574421578194035\n",
      "7 3 lbfgs 0.5638116243435407\n",
      "8 1 lbfgs 0.6000577839436991\n",
      "8 2 lbfgs 0.5743948862827518\n",
      "8 3 lbfgs 0.5906039942746659\n",
      "9 1 lbfgs 0.6121658819783979\n",
      "9 2 lbfgs 0.5911432517671663\n",
      "9 3 lbfgs 0.5879081921196418\n",
      "10 1 lbfgs 0.5937956997875\n",
      "10 2 lbfgs 0.572222164704299\n",
      "10 3 lbfgs 0.560686082416857\n",
      "11 1 lbfgs 0.5813656002412302\n",
      "11 2 lbfgs 0.56755294057507\n",
      "11 3 lbfgs 0.5862837062220302\n",
      "12 1 lbfgs 0.5906764668580288\n",
      "12 2 lbfgs 0.588778429312054\n",
      "12 3 lbfgs 0.565541098425533\n",
      "13 1 lbfgs 0.5989128627188088\n",
      "13 2 lbfgs 0.6046928747803174\n",
      "13 3 lbfgs 0.586555235755902\n",
      "14 1 lbfgs 0.5876453981203719\n",
      "14 2 lbfgs 0.6002997097214207\n",
      "14 3 lbfgs 0.5707657569631917\n",
      "15 1 lbfgs 0.5883516013852617\n",
      "15 2 lbfgs 0.5849428825452372\n",
      "15 3 lbfgs 0.585512876178003\n",
      "16 1 lbfgs 0.5889424632395762\n",
      "16 2 lbfgs 0.5773512176688158\n",
      "16 3 lbfgs 0.5838495656821611\n",
      "17 1 lbfgs 0.5945091017799784\n",
      "17 2 lbfgs 0.5721456478919538\n",
      "17 3 lbfgs 0.564174715221572\n",
      "18 1 lbfgs 0.6034478993304051\n",
      "18 2 lbfgs 0.5716373691934578\n",
      "18 3 lbfgs 0.5698741662417529\n",
      "19 1 lbfgs 0.5911896795158831\n",
      "19 2 lbfgs 0.6020195585384351\n",
      "19 3 lbfgs 0.5782293006654537\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()  \n",
    "# Don't cheat - fit only on training data\n",
    "scaler.fit(X)  \n",
    "X_train = scaler.transform(X) \n",
    "X_test = scaler.transform(X_val) \n",
    "\n",
    "(X_train1, \n",
    " X_test1, \n",
    " y_train1, y_test1) = train_test_split(X_train, Y, \n",
    "                                     test_size=0.3, \n",
    "                                     random_state=0)\n",
    "\n",
    "solvers={'lbfgs', 'sgd', 'adam'}\n",
    "for k in solvers:\n",
    "    for i in range(2,20):\n",
    "        for j in range(1,4):\n",
    "            clf = MLPClassifier(solver=k, alpha=1e-5,hidden_layer_sizes=(i, j),max_iter=1000, random_state=1,activation='tanh',learning_rate='adaptive')\n",
    "            clf.fit(X_train1, y_train1)\n",
    "            print i , j,k,roc_auc_score(y_test1,clf.predict(X_test1))\n",
    " \n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', alpha=1e-05, batch_size='auto',\n",
       "       beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(6, 2), learning_rate='adaptive',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
       "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=1,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "scaler = StandardScaler()  \n",
    "# Don't cheat - fit only on training data\n",
    "scaler.fit(X)  \n",
    "X_train = scaler.transform(X)  \n",
    "# apply same transformation to test data\n",
    "X_test = scaler.transform(X_val)  \n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(6, 2), random_state=1,activation='logistic',learning_rate='adaptive',verbose=1)\n",
    "clf.fit(X_train, Y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_to_file(clf.predict_proba(X_test)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn import svm\n",
    "#for kernel in ('linear', 'poly', 'rbf'):\n",
    "clf = svm.SVC(kernel='poly', gamma=2,class_weight='balanced')\n",
    "clf.fit(X_train1, y_train1)\n",
    "print roc_auc_score(y_test1,clf.predict(X_test1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='logistic', alpha=1e-05, batch_size='auto',\n",
       "       beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(5, 2), learning_rate='adaptive',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
       "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=1,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "scaler = StandardScaler()  \n",
    "# Don't cheat - fit only on training data\n",
    "scaler.fit(X)  \n",
    "X_train = scaler.transform(X)  \n",
    "# apply same transformation to test data\n",
    "X_test = scaler.transform(X_val)  \n",
    "clf = MLPRegressor(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(5, 2), random_state=1,activation='logistic',learning_rate='adaptive',verbose=1)\n",
    "clf.fit(X_train, Y)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_to_file(clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.699"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    " # MPL with select features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectKBest(k=76, score_func=<function chi2 at 0x000000000BA137B8>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector=SelectKBest(chi2, k=76)\n",
    "selector.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new=selector.transform(X)\n",
    "X_v=selector.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, \n",
    " X_test, \n",
    " y_train, y_test) = train_test_split(X_new, Y, \n",
    "                                     test_size=0.3, \n",
    "                                     random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7303058181248755"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MLPRegressor(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(3, 1), random_state=1,activation='tanh',learning_rate='invscaling',verbose=1)\n",
    "clf.fit(X_train, y_train)  \n",
    "roc_auc_score(y_test,clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='tanh', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(3, 1), learning_rate='invscaling',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
       "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=1,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_new,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_to_file(clf.predict(X_v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.74 fuck yeah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7323221898108724"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MLPRegressor(solver='lbfgs', alpha=1e-3,hidden_layer_sizes=(3, 1), random_state=1,activation='tanh',learning_rate='invscaling',learning_rate_init=0.00001,verbose=1)\n",
    "clf.fit(X_train, y_train)  \n",
    "roc_auc_score(y_test,clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7323554333731069"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MLPRegressor(solver='lbfgs', alpha=1e-2,hidden_layer_sizes=(3, 1), random_state=1,activation='tanh',learning_rate='invscaling',learning_rate_init=0.00001,verbose=1)\n",
    "clf.fit(X_train, y_train)  \n",
    "roc_auc_score(y_test,clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='tanh', alpha=0.01, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(3, 1), learning_rate='invscaling',\n",
       "       learning_rate_init=1e-05, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
       "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=1,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_new,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_to_file(clf.predict(X_v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.742 fuck yeah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPRegressor(solver='lbfgs', alpha=1e-1,hidden_layer_sizes=(4, 1), random_state=1,activation='logistic',learning_rate='invscaling',learning_rate_init=0.00001,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7228420317688746"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)  \n",
    "roc_auc_score(y_test,clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
